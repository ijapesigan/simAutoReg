# Generated by using Rcpp::compileAttributes() -> do not edit by hand
# Generator token: 10BE3573-1514-4C36-9D1C-5A225CD40393

#' Simulate Data from an Autoregressive Model with Constant Term
#'
#' This function generates synthetic time series data
#' from an autoregressive (AR) model.
#'
#' @author Ivan Jacob Agaloos Pesigan
#'
#' @param time Integer.
#'   Number of time points to simulate.
#' @param burn_in Integer.
#'   Number of burn-in periods before recording data.
#' @param constant Numeric.
#'   The constant term of the AR model.
#' @param coef Numeric vector.
#'   Autoregressive coefficients.
#' @param sd Numeric.
#'   The standard deviation of the random process noise.
#'
#' @return Numeric vector containing the simulated time series data.
#'
#' @examples
#' set.seed(42)
#' SimAR(time = 10, burn_in = 5, constant = 2, coef = c(0.5, -0.3), sd = 0.1)
#'
#' @details
#' The [simAutoReg::SimAR()] function generates synthetic time series data
#' from an autoregressive (AR) model.
#' The generated data follows the AR(p) model,
#' where `p` is the number of coefficients specified in `coef`.
#' The generated time series data includes a constant term
#' and autoregressive terms based on the provided coefficients.
#' Random noise, sampled from a normal distribution with mean 0
#' and standard deviation `sd`, is added to the time series.
#' A burn-in period is specified to exclude initial data points
#' from the output.
#'
#' The steps in generating the autoregressive time series with burn-in
#' are as follows:
#'
#' - Set the order of the AR model to `p` based on the length of `coef`.
#' - Create a vector data of size `time + burn_in`
#'   to store the generated AR time series data.
#' - Create a vector data of size `time + burn_in` of random process noise
#'   from a normal distribution with mean 0
#'   and standard deviation `sd`.
#' - Generate the autoregressive time series with burn-in using the formula:
#'   \deqn{Y_t = constant + \sum_{i=1}^{p} (coef[i] * Y_{t-i}) + noise_t}
#'   where \eqn{Y_t} is the time series data at time \eqn{t}, \eqn{constant}
#'   is the constant term,
#'   \eqn{coef[i]} are the autoregressive coefficients,
#'   \eqn{Y_{t-i}} are the lagged data points up to order `p`,
#'   and \eqn{noise_t} is the random noise at time \eqn{t}.
#' - Remove the burn-in period from the generated time series data.
#'
#' @importFrom Rcpp sourceCpp
#'
#' @family Simulation of Autoregressive Data Functions
#' @keywords simAutoReg sim
#' @export
SimAR <- function(time, burn_in, constant, coef, sd) {
    .Call(`_simAutoReg_SimAR`, time, burn_in, constant, coef, sd)
}

#' Simulate Data from a Vector Autoregressive (VAR) Model
#'
#' This function generates synthetic time series data
#' from a Vector Autoregressive (VAR) model.
#'
#' @author Ivan Jacob Agaloos Pesigan
#'
#' @param time Integer.
#'   Number of time points to simulate.
#' @param burn_in Integer.
#'   Number of burn-in observations to exclude before returning the results.
#' @param constant Numeric vector.
#'   The constant term vector of length `k`,
#'   where `k` is the number of variables.
#' @param coef Numeric matrix.
#'   Coefficient matrix with dimensions `k` by `(k * p)`.
#'   Each `k` by `k` block corresponds to the coefficient matrix
#'   for a particular lag.
#' @param chol_cov Numeric matrix.
#'   The Cholesky decomposition of the covariance matrix
#'   of the multivariate normal noise.
#'   It should have dimensions `k` by `k`.
#'
#' @return Numeric matrix containing the simulated time series data
#'   with dimensions `k` by `(time - burn_in)`,
#'   where `k` is the number of variables and
#'   time is the number of observations.
#'
#' @examples
#' set.seed(42)
#' time <- 50L
#' burn_in <- 10L
#' k <- 3
#' p <- 2
#' constant <- c(1, 1, 1)
#' coef <- matrix(
#'   data = c(
#'     0.4, 0.0, 0.0, 0.1, 0.0, 0.0,
#'     0.0, 0.5, 0.0, 0.0, 0.2, 0.0,
#'     0.0, 0.0, 0.6, 0.0, 0.0, 0.3
#'   ),
#'   nrow = k,
#'   byrow = TRUE
#' )
#' chol_cov <- chol(diag(3))
#' y <- SimVAR(
#'   time = time,
#'   burn_in = burn_in,
#'   constant = constant,
#'   coef = coef,
#'   chol_cov = chol_cov
#' )
#' head(y)
#'
#' @details
#' The [simAutoReg::SimVAR()] function generates synthetic time series data
#' from a Vector Autoregressive (VAR) model.
#' The VAR model is defined by the constant term `constant`,
#' the coefficient matrix `coef`,
#' and the Cholesky decomposition of the covariance matrix
#' of the multivariate normal process noise `chol_cov`.
#' The generated time series data follows a VAR(p) process,
#' where `p` is the number of lags specified by the size of `coef`.
#' The generated data includes a burn-in period,
#' which is excluded before returning the results.
#'
#' The steps involved in generating the VAR time series data are as follows:
#'
#' - Extract the number of variables `k` and the number of lags `p`
#'   from the input.
#' - Create a matrix `data` of size `k` by (`time + burn_in`)
#'   to store the generated VAR time series data.
#' - Set the initial values of the matrix `data`
#'   using the constant term `constant`.
#' - For each time point starting from the `p`-th time point
#'   to `time + burn_in - 1`:
#'   * Generate a vector of random noise
#'     from a multivariate normal distribution
#'     with mean 0 and covariance matrix `chol_cov`.
#'   * Generate the VAR time series values for each variable `j` at time `t`
#'     using the formula:
#'     \deqn{Y_{tj} = constant_j +
#'     \sum_{l = 1}^{p} \sum_{m = 1}^{k} (coef_{jm} * Y_{im}) +
#'     \text{noise}_{j}}
#'     where \eqn{Y_{tj}} is the value of variable `j` at time `t`,
#'     \eqn{constant_j} is the constant term for variable `j`,
#'     \eqn{coef_{jm}} are the coefficients for variable `j`
#'     from lagged variables up to order `p`,
#'     \eqn{Y_{tm}} are the lagged values of variable `m`
#'     up to order `p` at time `t`,
#'     and \eqn{noise_{j}} is the element `j`
#'     from the generated vector of random process noise.
#' - Transpose the matrix `data` and return only
#'   the required time period after the burn-in period,
#'   which is from column `burn_in` to column `time + burn_in - 1`.
#'
#' @importFrom Rcpp sourceCpp
#'
#' @family Simulation of Autoregressive Data Functions
#' @keywords simAutoReg sim
#' @export
SimVAR <- function(time, burn_in, constant, coef, chol_cov) {
    .Call(`_simAutoReg_SimVAR`, time, burn_in, constant, coef, chol_cov)
}

#' Simulate Data from a Vector Autoregressive Zero-Inflated Poisson (VARZIP)
#' Model
#'
#' This function generates synthetic time series data
#' from a Vector Autoregressive Zero-Inflated Poisson (VARZIP) model.
#'
#' @author Ivan Jacob Agaloos Pesigan
#'
#' @param time Integer.
#'   Number of time points to simulate.
#' @param burn_in Integer.
#'   Number of burn-in observations to exclude before returning the results.
#' @param constant Numeric vector.
#'   The constant term vector of length `k`,
#'   where `k` is the number of variables.
#' @param coef Numeric matrix.
#'   Coefficient matrix with dimensions `k` by `(k * p)`.
#'   Each `k` by `k` block corresponds to the coefficient matrix
#'   for a particular lag.
#' @param chol_cov Numeric matrix.
#'   The Cholesky decomposition of the covariance matrix
#'   of the multivariate normal noise.
#'   It should have dimensions `k` by `k`.
#'
#' @return Numeric matrix containing the simulated time series data
#'   with dimensions `k` by `(time - burn_in)`,
#'   where `k` is the number of variables
#'   and time is the number of observations.
#'
#' @examples
#' set.seed(42)
#' time <- 50L
#' burn_in <- 10L
#' k <- 3
#' p <- 2
#' constant <- c(1, 1, 1)
#' coef <- matrix(
#'   data = c(
#'     0.4, 0.0, 0.0, 0.1, 0.0, 0.0,
#'     0.0, 0.5, 0.0, 0.0, 0.2, 0.0,
#'     0.0, 0.0, 0.6, 0.0, 0.0, 0.3
#'   ),
#'   nrow = k,
#'   byrow = TRUE
#' )
#' chol_cov <- chol(diag(3))
#' y <- SimVARZIP(
#'   time = time,
#'   burn_in = burn_in,
#'   constant = constant,
#'   coef = coef,
#'   chol_cov = chol_cov
#' )
#' head(y)
#'
#' @details
#' The [simAutoReg::SimVARZIP()] function generates synthetic time series data
#' from a Vector Autoregressive (VAR)
#' with Zero-Inflated Poisson (ZIP) model for the first observed variable.
#' See [simAutoReg::SimVAR()] for more details on generating data for VAR(p).
#' The `SimVARZIP` function goes further by using the generated values
#' for the first variable to generate data from the ZIP model.
#' The exponential of the values from the first variable
#' from the original VAR(p) model
#' are used as the `intensity` parameter in the Poisson distribution
#' in the ZIP model.
#' Data from the ZIP model are used to replace the original values
#' for the first variable.
#' Values for the rest of the variables are unchanged.
#' The generated data includes a burn-in period,
#' which is excluded before returning the results.
#'
#' The steps involved in generating the time series data are as follows:
#'
#' - Extract the number of variables `k`
#'   and the number of lags `p` from the input.
#' - Create a matrix `data` of size `k` x (`time + burn_in`)
#'   to store the generated data.
#' - Set the initial values of the matrix `data`
#'   using the constant term `constant`.
#' - For each time point starting from the `p`-th time point
#'   to `time + burn_in - 1`:
#'   * Generate a vector of random process noise
#'     from a multivariate normal distribution
#'     with mean 0 and covariance matrix `chol_cov`.
#'   * Generate the VAR time series values for each variable `j`
#'     at time `t` by applying the autoregressive terms
#'     for each lag `lag` and each variable `l`.
#'     - Add the generated noise to the VAR time series values.
#'     - For the first variable,
#'       apply the Zero-Inflated Poisson (ZIP) model:
#'       * Compute the intensity `intensity`
#'         as the exponential of the first variable's value at time `t`.
#'       * Sample a random value `u`
#'         from a uniform distribution on \[0, 1\].
#'       * If `u` is less than `intensity / (1 + intensity)`,
#'         set the first variable's value to zero (inflation).
#'       * Otherwise, sample the first variable's value
#'         from a Poisson distribution
#'         with mean `intensity` (count process).
#' - Transpose the data matrix `data` and return only
#'   the required time period after burn-in as a numeric matrix.
#'
#' @importFrom Rcpp sourceCpp
#'
#' @family Simulation of Autoregressive Data Functions
#' @keywords simAutoReg sim
#' @export
SimVARZIP <- function(time, burn_in, constant, coef, chol_cov) {
    .Call(`_simAutoReg_SimVARZIP`, time, burn_in, constant, coef, chol_cov)
}

#' Simulate Multivariate Normal Random Numbers
#'
#' This function generates multivariate normal random numbers.
#'
#' @author Ivan Jacob Agaloos Pesigan
#'
#' @param n Integer.
#'   Number of samples to generate.
#' @param location Numeric vector.
#'   Mean vector of length `k`, where `k` is the number of variables.
#' @param chol_scale Numeric matrix.
#'   Cholesky decomposition of the covariance matrix of dimensions `k` by `k`.
#'
#' @return Matrix containing the simulated multivariate normal random numbers,
#'   with dimensions `n` by `k`, where `n` is the number of samples
#'   and `k` is the number of variables.
#'
#' @examples
#' set.seed(42)
#' n <- 1000L
#' location <- c(0.5, -0.2, 0.1)
#' scale <- matrix(
#'   data = c(1.0, 0.3, 0.3, 0.3, 1.0, 0.2, 0.3, 0.2, 1.0),
#'   nrow = 3,
#'   byrow = TRUE
#' )
#' chol_scale <- chol(scale)
#' y <- SimMVN(n = n, location = location, chol_scale = chol_scale)
#' colMeans(y)
#' var(y)
#'
#' @details
#' The [simAutoReg::SimMVN()] function generates
#' multivariate normal random numbers
#' using the Cholesky decomposition method.
#' Given the number of samples `n`, the mean vector `location` of length `k`
#' (where `k` is the number of variables),
#' and the Cholesky decomposition `chol_scale` of the covariance matrix
#' of dimensions `k` by `k`,
#' the function produces a matrix of multivariate normal random numbers.
#'
#' The steps involved in generating multivariate normal random numbers
#' are as follows:
#'
#' - Determine the number of variables `k` from the length of the mean vector.
#' - Generate random data from a standard multivariate normal distribution,
#'   resulting in an `n` by `k` matrix of random numbers.
#' - Transform the standard normal random data
#'   into multivariate normal random data
#'   using the Cholesky decomposition `chol_scale`.
#' - Add the mean vector `location` to the transformed data
#'   to obtain the final simulated multivariate normal random numbers.
#' - The function returns a matrix of simulated
#'   multivariate normal random numbers
#'   with dimensions `n` by `k`,
#'   where `n` is the number of samples and `k` is the number of variables.
#'   This matrix can be used for various statistical analyses and simulations.
#'
#' @seealso
#' The [chol()] function in R to obtain the Cholesky decomposition
#' of a covariance matrix.
#'
#' @importFrom Rcpp sourceCpp
#'
#' @family Simulation of Autoregressive Data Functions
#' @keywords simAutoReg sim
#' @export
SimMVN <- function(n, location, chol_scale) {
    .Call(`_simAutoReg_SimMVN`, n, location, chol_scale)
}

#' Generate Random Data for the Variance Vector
#'
#' This function generates random data for the variance vector given by
#' \deqn{
#'   \boldsymbol{\sigma^{2}} =
#'   \exp \left( \boldsymbol{\mu} + \boldsymbol{\varepsilon} \right)
#'   \quad
#'   \text{with}
#'   \quad
#'   \boldsymbol{\varepsilon} \sim
#'   \mathcal{N} \left( \boldsymbol{0}, \boldsymbol{\Sigma} \right)
#' }.
#'
#' @author Ivan Jacob Agaloos Pesigan
#'
#' @param n Integer.
#'   Number of samples to generate.
#' @param location Numeric vector.
#'   The constant term \eqn{\boldsymbol{\mu}}.
#' @param chol_scale Numeric matrix.
#'   Cholesky decomposition of the covariance matrix \eqn{\boldsymbol{\Sigma}}
#'   for the multivariate normal random error \eqn{\boldsymbol{\varepsilon}}.
#'
#' @return Matrix with each row containing the simulated variance vector
#'   for each sample.
#'
#' @details
#' The [simAutoReg::SimVariance()] function generates random data
#' for the variance vector
#' based on the exponential of a multivariate normal distribution.
#' Given the number of samples `n`,
#' the constant term \eqn{\boldsymbol{\mu}} represented
#' by the `location` vector,
#' and the Cholesky decomposition matrix \eqn{\boldsymbol{\Sigma}}
#' for the multivariate normal random error \eqn{\boldsymbol{\varepsilon}},
#' the function simulates \eqn{n} independent samples
#' of the variance vector \eqn{\boldsymbol{\sigma^{2}}}.
#' Each sample of the variance vector \eqn{\boldsymbol{\sigma^{2}}}
#' is obtained by
#' calculating the exponential of random variations
#' to the mean vector \eqn{\boldsymbol{\mu}}.
#' The random variations are generated using the Cholesky decomposition
#' of the covariance matrix \eqn{\boldsymbol{\Sigma}}.
#' Finally, the function returns a matrix with each column
#' containing the simulated
#' variance vector for each sample.
#'
#' @examples
#' set.seed(42)
#' n <- 100
#' location <- c(0.5, -0.2, 0.1)
#' chol_scale <- chol(
#'   matrix(
#'     data = c(1.0, 0.3, 0.3, 0.3, 1.0, 0.2, 0.3, 0.2, 1.0),
#'     nrow = 3,
#'     byrow = TRUE
#'   )
#' )
#' SimVariance(n = n, location = location, chol_scale = chol_scale)
#'
#' @importFrom Rcpp sourceCpp
#'
#' @family Simulation of Autoregressive Data Functions
#' @keywords simAutoReg sim
#' @export
SimVariance <- function(n, location, chol_scale) {
    .Call(`_simAutoReg_SimVariance`, n, location, chol_scale)
}

#' Create Y and X Matrices
#'
#' This function creates the dependent variable (Y)
#' and predictor variable (X) matrices.
#'
#' @author Ivan Jacob Agaloos Pesigan
#'
#' @param data Numeric matrix.
#'   The time series data with dimensions `t` by `k`,
#'   where `t` is the number of observations
#'   and `k` is the number of variables.
#' @param p Integer.
#'   The order of the VAR model (number of lags).
#'
#' @return List containing the dependent variable (Y)
#' and predictor variable (X) matrices.
#' Note that the resulting matrices will have `t - p` rows.
#'
#' @examples
#' yx <- YX(data = vark3p2, p = 2)
#' str(yx)
#'
#' @details
#' The [simAutoReg::YX()] function creates the `Y` and `X` matrices
#' required for fitting a Vector Autoregressive (VAR) model.
#' Given the input `data` matrix with dimensions `t` by `k`,
#' where `t` is the number of observations and `k` is the number of variables,
#' and the order of the VAR model `p` (number of lags),
#' the function constructs lagged predictor matrix `X`
#' and the dependent variable matrix `Y`.
#'
#' The steps involved in creating the `Y` and `X` matrices are as follows:
#'
#' - Determine the number of observations `t` and the number of variables `k`
#'   from the input data matrix.
#' - Create matrices `X` and `Y` to store lagged variables
#'   and the dependent variable, respectively.
#' - Populate the matrices `X` and `Y` with the appropriate lagged data.
#'   The predictors matrix `X` contains a column of ones
#'   and the lagged values of the dependent variables,
#'   while the dependent variable matrix `Y` contains the original values
#'   of the dependent variables.
#' - The function returns a list containing the `Y` and `X` matrices,
#'   which can be used for further analysis and estimation
#'   of the VAR model parameters.
#'
#' @seealso
#' The [simAutoReg::SimVAR()] function for simulating time series data
#' from a VAR model.
#'
#' @importFrom Rcpp sourceCpp
#'
#' @family Simulation of Autoregressive Data Functions
#' @keywords simAutoReg utils
#' @export
YX <- function(data, p) {
    .Call(`_simAutoReg_YX`, data, p)
}

#' Standardize Matrix
#'
#' This function standardizes the given matrix by centering the columns
#' and scaling them to have unit variance.
#'
#' @author Ivan Jacob Agaloos Pesigan
#'
#' @param X Numeric matrix.
#'   The matrix to be standardized.
#'
#' @return Numeric matrix with standardized values.
#'
#' @examples
#' std <- StdMat(vark3p2)
#' colMeans(std)
#' var(std)
#'
#' @importFrom Rcpp sourceCpp
#'
#' @family Simulation of Autoregressive Data Functions
#' @keywords simAutoReg utils
#' @export
StdMat <- function(X) {
    .Call(`_simAutoReg_StdMat`, X)
}

#' Return Standardized Estimates to the Original Scale
#'
#' @author Ivan Jacob Agaloos Pesigan
#'
#' @param coef_std Numeric matrix.
#'   Standardized estimates of the autoregression
#'   and cross regression coefficients.
#' @param Y Numeric matrix.
#'   Matrix of dependent variables (Y).
#' @param X Numeric matrix.
#'   Matrix of predictors (X).
#'
#' @examples
#' Ystd <- StdMat(vark3p2yx$Y)
#' Xstd <- StdMat(vark3p2yx$X[, -1])
#' coef_std <- FitVAROLS(Y = Ystd, X = Xstd)
#' OrigScale(coef_std = coef_std, Y = vark3p2yx$Y, X = vark3p2yx$X[, -1])
#' FitVAROLS(Y = vark3p2yx$Y, X = vark3p2yx$X[, -1])
#'
#' @importFrom Rcpp sourceCpp
#'
#' @family Simulation of Autoregressive Data Functions
#' @keywords simAutoReg utils
#' @export
OrigScale <- function(coef_std, Y, X) {
    .Call(`_simAutoReg_OrigScale`, coef_std, Y, X)
}

#' Fit Vector Autoregressive (VAR) Model Parameters using OLS
#'
#' This function estimates the parameters of a VAR model
#' using the Ordinary Least Squares (OLS) method.
#' The OLS method is used to estimate the autoregressive
#' and cross-regression coefficients.
#'
#' @author Ivan Jacob Agaloos Pesigan
#'
#' @param Y Numeric matrix.
#'   Matrix of dependent variables (Y).
#' @param X Numeric matrix.
#'   Matrix of predictors (X).
#'
#' @return Matrix of estimated autoregressive
#' and cross-regression coefficients.
#'
#' @examples
#' FitVAROLS(Y = vark3p2yx$Y, X = vark3p2yx$X)
#'
#' @details
#' The [simAutoReg::FitVAROLS()] function estimates the parameters
#' of a Vector Autoregressive (VAR) model
#' using the Ordinary Least Squares (OLS) method.
#' Given the input matrices `Y` and `X`,
#' where `Y` is the matrix of dependent variables,
#' and `X` is the matrix of predictors,
#' the function computes the autoregressive and cross-regression coefficients
#' of the VAR model.
#' Note that if the first column of `X` is a vector of ones,
#' the constant vector is also estimated.
#'
#' The steps involved in estimating the VAR model parameters
#' using OLS are as follows:
#'
#' - Compute the QR decomposition of the lagged predictor matrix `X`
#'   using the `qr` function from the Armadillo library.
#' - Extract the `Q` and `R` matrices from the QR decomposition.
#' - Solve the linear system `R * coef = Q.t() * Y`
#'   to estimate the VAR model coefficients `coef`.
#' - The function returns a matrix containing the estimated
#'   autoregressive and cross-regression coefficients of the VAR model.
#'
#' @seealso
#' The `qr` function from the Armadillo library for QR decomposition.
#'
#' @importFrom Rcpp sourceCpp
#'
#' @family Simulation of Autoregressive Data Functions
#' @keywords simAutoReg fit
#' @export
FitVAROLS <- function(Y, X) {
    .Call(`_simAutoReg_FitVAROLS`, Y, X)
}

#' Parametric Bootstrap for the Vector Autoregressive Model
#' Using Ordinary Least Squares
#'
#' @author Ivan Jacob Agaloos Pesigan
#'
#' @param data Numeric matrix.
#'   The time series data with dimensions `t` by `k`,
#'   where `t` is the number of observations
#'   and `k` is the number of variables.
#' @param p Integer.
#'   The order of the VAR model (number of lags).
#' @param B Integer.
#'   Number of bootstrap samples to generate.
#' @param burn_in Integer.
#'   Number of burn-in observations to exclude before returning the results
#'   in the simulation step.
#'
#' @return List containing the estimates (`est`)
#' and bootstrap estimates (`boot`).
#'
#' @examples
#' pb <- PBootVAROLS(data = vark3p2, p = 2, B = 10)
#' str(pb)
#'
#' @importFrom Rcpp sourceCpp
#'
#' @family Simulation of Autoregressive Data Functions
#' @keywords simAutoReg pb
#' @export
PBootVAROLS <- function(data, p, B = 1000L, burn_in = 200L) {
    .Call(`_simAutoReg_PBootVAROLS`, data, p, B, burn_in)
}

#' Fit Vector Autoregressive (VAR) Model Parameters using Lasso Regularization
#'
#' This function estimates the parameters of a VAR model
#' using the Lasso regularization method with cyclical coordinate descent.
#' The Lasso method is used to estimate the autoregressive
#' and cross-regression coefficients with sparsity.
#'
#' @author Ivan Jacob Agaloos Pesigan
#'
#' @param Ystd Numeric matrix.
#'   Matrix of standardized dependent variables (Y).
#' @param Xstd Numeric matrix.
#'   Matrix of standardized predictors (X).
#' @param lambda Lasso hyperparameter.
#'   The regularization strength controlling the sparsity.
#' @param max_iter Integer.
#'   The maximum number of iterations for the coordinate descent algorithm.
#'   Default is 10000.
#' @param tol Numeric.
#'   Convergence tolerance. The algorithm stops when the change in coefficients
#'   between iterations is below this tolerance. Default is 1e-6.
#'
#' @return Matrix of estimated autoregressive and
#' cross-regression coefficients.
#'
#' @examples
#' Ystd <- StdMat(vark3p2yx$Y)
#' Xstd <- StdMat(vark3p2yx$X[, -1])
#' lambda <- 73.90722
#' FitVARLasso(Ystd = Ystd, Xstd = Xstd, lambda = lambda)
#'
#' @details
#' The [simAutoReg::FitVARLasso()] function estimates the parameters
#' of a Vector Autoregressive (VAR) model
#' using the Lasso regularization method.
#' Given the input matrices `Ystd` and `Xstd`,
#' where `Ystd` is the matrix of standardized dependent variables,
#' and `Xstd` is the matrix of standardized predictors,
#' the function computes the autoregressive and cross-regression coefficients
#' of the VAR model with sparsity induced by the Lasso regularization.
#'
#' The steps involved in estimating the VAR model parameters
#' using Lasso are as follows:
#'
#' - **Initialization**: The function initializes the coefficient matrix
#'   `beta` with OLS estimates.
#'   The `beta` matrix will store the estimated autoregressive and
#'   cross-regression coefficients.
#' - **Coordinate Descent Loop**: The function performs
#'   the cyclical coordinate descent algorithm
#'   to estimate the coefficients iteratively.
#'   The loop iterates `max_iter` times (default is 10000),
#'   or until convergence is achieved.
#'   The outer loop iterates over the predictor variables
#'   (columns of `Xstd`),
#'   while the inner loop iterates over the outcome variables
#'   (columns of `Ystd`).
#' - **Coefficient Update**: For each predictor variable (column of `Xstd`),
#'   the function iteratively updates the corresponding column of `beta`
#'   using the coordinate descent algorithm with L1 norm regularization
#'   (Lasso).
#'   The update involves calculating the soft-thresholded value `c`,
#'   which encourages sparsity in the coefficients.
#'   The algorithm continues until the change in coefficients
#'   between iterations is below the specified tolerance `tol`
#'   or when the maximum number of iterations is reached.
#' - **Convergence Check**: The function checks for convergence
#'   by comparing the current `beta`
#'   matrix with the previous iteration's `beta_old`.
#'   If the maximum absolute difference between `beta` and `beta_old`
#'   is below the tolerance `tol`,
#'   the algorithm is considered converged, and the loop exits.
#'
#' @seealso
#' The [simAutoReg::FitVAROLS()] function for estimating VAR model parameters
#' using OLS.
#'
#' @importFrom Rcpp sourceCpp
#'
#' @family Simulation of Autoregressive Data Functions
#' @keywords simAutoReg fit
#' @export
FitVARLasso <- function(Ystd, Xstd, lambda, max_iter = 10000L, tol = 1e-5) {
    .Call(`_simAutoReg_FitVARLasso`, Ystd, Xstd, lambda, max_iter, tol)
}

#' Fit Vector Autoregressive (VAR) Model Parameters using Lasso Regularization
#' with Lambda Search
#'
#' @author Ivan Jacob Agaloos Pesigan
#'
#' @param Ystd Numeric matrix.
#'   Matrix of standardized dependent variables (Y).
#' @param Xstd Numeric matrix.
#'   Matrix of standardized predictors (X).
#' @param lambdas Numeric vector.
#'   Vector of lambda hyperparameters for Lasso regularization.
#' @param max_iter Integer.
#'   The maximum number of iterations for the coordinate descent algorithm.
#'   Default is 10000.
#' @param tol Numeric.
#'   Convergence tolerance. The algorithm stops when the change in coefficients
#'   between iterations is below this tolerance. Default is 1e-5.
#' @param crit Character string.
#'   Information criteria to use.
#'   Valid values include `"aic"`, `"bic"`, and `"ebic"`.
#'
#' @return Matrix of estimated autoregressive
#' and cross-regression coefficients.
#'
#' @examples
#' Ystd <- StdMat(vark3p2yx$Y)
#' Xstd <- StdMat(vark3p2yx$X[, -1])
#' lambdas <- LambdaSeq(Y = Ystd, X = Xstd, n_lambdas = 100)
#' FitVARLassoSearch(Ystd = Ystd, Xstd = Xstd, lambdas = lambdas)
#'
#' @family Simulation of Autoregressive Data Functions
#' @keywords simAutoReg fit
#' @export
FitVARLassoSearch <- function(Ystd, Xstd, lambdas, crit = "ebic", max_iter = 10000L, tol = 1e-5) {
    .Call(`_simAutoReg_FitVARLassoSearch`, Ystd, Xstd, lambdas, crit, max_iter, tol)
}

#' Function to generate the sequence of lambdas
#'
#' @author Ivan Jacob Agaloos Pesigan
#'
#' @param Y Numeric matrix.
#'   Matrix of dependent variables (Y).
#' @param X Numeric matrix.
#'   Matrix of predictors (X).
#' @param n_lambdas Integer.
#'   Number of lambdas to generate.
#'
#' @return Returns a vector of lambdas.
#'
#' @examples
#' Ystd <- StdMat(vark3p2yx$Y)
#' Xstd <- StdMat(vark3p2yx$X[, -1])
#' LambdaSeq(Y = Ystd, X = Xstd, n_lambdas = 100)
#'
#' @family Simulation of Autoregressive Data Functions
#' @keywords simAutoReg fit
#' @export
LambdaSeq <- function(Y, X, n_lambdas = 100L) {
    .Call(`_simAutoReg_LambdaSeq`, Y, X, n_lambdas)
}

#' Compute AIC, BIC, and EBIC for Lasso Regularization
#'
#' This function computes the Akaike Information Criterion (AIC),
#' Bayesian Information Criterion (BIC),
#' and Extended Bayesian Information Criterion (EBIC)
#' for a given matrix of predictors `X`, a matrix of outcomes `Y`,
#' and a vector of lambda hyperparameters for Lasso regularization.
#'
#' @author Ivan Jacob Agaloos Pesigan
#'
#' @param Ystd Numeric matrix.
#'   Matrix of standardized dependent variables (Y).
#' @param Xstd Numeric matrix.
#'   Matrix of standardized predictors (X).
#' @param lambdas Numeric vector.
#'   Vector of lambda hyperparameters for Lasso regularization.
#' @param max_iter Integer.
#'   The maximum number of iterations for the coordinate descent algorithm.
#'   Default is 10000.
#' @param tol Numeric.
#'   Convergence tolerance. The algorithm stops when the change in coefficients
#'   between iterations is below this tolerance. Default is 1e-5.
#'
#' @return List containing two elements:
#'   - Element 1: Matrix with columns for
#'     lambda, AIC, BIC, and EBIC values.
#'   - Element 2: List of matrices containing
#'     the estimated autoregressive
#'     and cross-regression coefficients for each lambda.
#'
#' @examples
#' Ystd <- StdMat(vark3p2yx$Y)
#' Xstd <- StdMat(vark3p2yx$X[, -1])
#' lambdas <- 10^seq(-5, 5, length.out = 100)
#' search <- SearchVARLasso(Ystd = Ystd, Xstd = Xstd, lambdas = lambdas)
#' plot(x = 1:nrow(search$criteria), y = search$criteria[, 4],
#'   type = "b", xlab = "lambda", ylab = "EBIC")
#'
#' @family Simulation of Autoregressive Data Functions
#' @keywords simAutoReg fit
#' @export
SearchVARLasso <- function(Ystd, Xstd, lambdas, max_iter = 10000L, tol = 1e-5) {
    .Call(`_simAutoReg_SearchVARLasso`, Ystd, Xstd, lambdas, max_iter, tol)
}

#' Parametric Bootstrap for the Vector Autoregressive Model
#' Using Lasso Regularization
#' @author Ivan Jacob Agaloos Pesigan
#'
#' @param data Numeric matrix.
#'   The time series data with dimensions `t` by `k`,
#'   where `t` is the number of observations
#'   and `k` is the number of variables.
#' @param p Integer.
#'   The order of the VAR model (number of lags).
#' @param B Integer.
#'   Number of bootstrap samples to generate.
#' @param burn_in Integer.
#'   Number of burn-in observations to exclude before returning the results
#'   in the simulation step.
#'
#' @return List containing the estimates (`est`)
#' and bootstrap estimates (`boot`).
#'
#' @examples
#' pb <- PBootVARLasso(data = vark3p2, p = 2, B = 10)
#' str(pb)
#'
#' @importFrom Rcpp sourceCpp
#'
#' @family Simulation of Autoregressive Data Functions
#' @keywords simAutoReg pb
#' @export
PBootVARLasso <- function(data, p, B = 1000L, burn_in = 200L) {
    .Call(`_simAutoReg_PBootVARLasso`, data, p, B, burn_in)
}

